{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL Earthquake Prediction Kaggle Competition 2019\n",
    "### Eric Yap, Joel Huang, Kyra Wang\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we present our work for the LANL Earthquake Prediction Kaggle Competition 2019. The goal of this competition is to use seismic signals to predict the timing of laboratory earthquakes. The data comes from a well-known experimental set-up used to study earthquake physics. The `acoustic_data` input signal is used to predict the time remaining before the next laboratory earthquake (`time_to_failure`).\n",
    "\n",
    "The training data is a single, continuous segment of experimental data. The test data consists of a folder containing many small segments. The data within each test file is continuous, but the test files do not represent a continuous segment of the experiment; thus, the predictions cannot be assumed to follow the same regular pattern seen in the training file.\n",
    "\n",
    "For each `seg_id` in the test folder, we need to predict a single `time_to_failure` corresponding to the time between the last row of the segment and the next laboratory earthquake.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Data wrangling imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Utility imports\n",
    "import ast\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tick\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "\n",
    "# Custom stuff\n",
    "from series_data import LANLDataset, FeatureGenerator\n",
    "\n",
    "# Setting the seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "else:\n",
    "    torch.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "As the training data and the test data are formatted differently, we must either preprocess the data such that the formats of both sets are the same, or ensure that our model is capable of predicting on the two different formats. We went with the first option because it is less time consuming to implement.\n",
    "\n",
    "We did this by splitting the training data into segments the same size as the test data segments, i.e. 150000 data points each. Each segment is labeled with a single `time_to_failure` corresponding to the time between the last row of the segment and the next laboratory earthquake. We then put each of these segments into a single dataframe, and saved this as a pickle file to be used as our training data.\n",
    "\n",
    "Following this, we merged the separate test segments into another single dataframe, and saved this as a pickle file to be used as our test data.\n",
    "\n",
    "As the dataset is massive, we used Joblib to help run the functions as a pipeline jobs with parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_df = pd.read_pickle('./data/train_features.pkl')\n",
    "trainval_df = trainval_df[:-2]\n",
    "train_segments = np.array([seg for seg in trainval_df['segment'].to_numpy()])\n",
    "train_labels = trainval_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('./data/test_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we split the training data further into a 80/20 training/validation split. We then create dataloaders that will help load the data into the model in parallel using multiprocessing workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Feature Extraction\n",
    "https://www.kaggle.com/gpreda/lanl-earthquake-eda-and-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3118c5d7c164e32aa630c270c545ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4193), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:53: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "def create_features(seg_id, seg, X):\n",
    "    xc = pd.Series(seg)\n",
    "    zc = np.fft.fft(xc)\n",
    "    \n",
    "    #FFT transform values\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    X.loc[seg_id, 'Rmean'] = realFFT.mean()\n",
    "    X.loc[seg_id, 'Rstd'] = realFFT.std()\n",
    "    X.loc[seg_id, 'Rmax'] = realFFT.max()\n",
    "    X.loc[seg_id, 'Rmin'] = realFFT.min()\n",
    "    X.loc[seg_id, 'Imean'] = imagFFT.mean()\n",
    "    X.loc[seg_id, 'Istd'] = imagFFT.std()\n",
    "    X.loc[seg_id, 'Imax'] = imagFFT.max()\n",
    "    X.loc[seg_id, 'Imin'] = imagFFT.min()\n",
    "    X.loc[seg_id, 'Rmean_last_5000'] = realFFT[-5000:].mean()\n",
    "    X.loc[seg_id, 'Rstd__last_5000'] = realFFT[-5000:].std()\n",
    "    X.loc[seg_id, 'Rmax_last_5000'] = realFFT[-5000:].max()\n",
    "    X.loc[seg_id, 'Rmin_last_5000'] = realFFT[-5000:].min()\n",
    "    X.loc[seg_id, 'Rmean_last_15000'] = realFFT[-15000:].mean()\n",
    "    X.loc[seg_id, 'Rstd_last_15000'] = realFFT[-15000:].std()\n",
    "    X.loc[seg_id, 'Rmax_last_15000'] = realFFT[-15000:].max()\n",
    "    X.loc[seg_id, 'Rmin_last_15000'] = realFFT[-15000:].min()\n",
    "    \n",
    "    X.loc[seg_id, 'mean_change_abs'] = np.mean(np.diff(xc))\n",
    "    X.loc[seg_id, 'mean_change_rate'] = np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0])\n",
    "    \n",
    "    for windows in [10, 100]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "        \n",
    "        X.loc[seg_id, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X.loc[seg_id, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X.loc[seg_id, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X.loc[seg_id, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X.loc[seg_id, 'q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X.loc[seg_id, 'q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X.loc[seg_id, 'q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X.loc[seg_id, 'q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X.loc[seg_id, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "        X.loc[seg_id, 'av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "        X.loc[seg_id, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "        X.loc[seg_id, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X.loc[seg_id, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X.loc[seg_id, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X.loc[seg_id, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X.loc[seg_id, 'q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X.loc[seg_id, 'q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X.loc[seg_id, 'q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X.loc[seg_id, 'q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X.loc[seg_id, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "        X.loc[seg_id, 'av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "        X.loc[seg_id, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()\n",
    "\n",
    "rows = 150000\n",
    "segments = train_segments.shape[0]\n",
    "\n",
    "train_features = pd.DataFrame(index=range(segments), dtype=np.float64)\n",
    "        \n",
    "for seg_id in tqdm_notebook(range(segments)):\n",
    "    seg = train_segments[seg_id]\n",
    "    create_features(seg_id, seg, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = ((train_features - train_features.mean()) / train_features.std()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4193, 62)\n"
     ]
    }
   ],
   "source": [
    "normalized_features = np.load('./data/normalized_time_series_features.npy')\n",
    "print(normalized_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 8\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 16}\n",
    "\n",
    "trainval_set = LANLDataset(normalized_features, train_labels, spec=False)\n",
    "train_set, val_set = trainval_set.train_val_split(0.7, 0.3)\n",
    "\n",
    "datasets = {\n",
    "    'train': train_set,\n",
    "    'val' : val_set\n",
    "}\n",
    "\n",
    "dataloaders = {phase: data.DataLoader(dataset, **params)\n",
    "               for phase, dataset in datasets.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LANLModel(nn.Module):\n",
    "    def __init__(self, device, input_dim=1, hidden_dim=64, output_dim=1, batch_size=64, num_layers=1):\n",
    "        super(LANLModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.LSTMCell(self.input_dim, self.hidden_dim)\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros(batch_size, self.hidden_dim).to(self.device),\n",
    "            torch.zeros(batch_size, self.hidden_dim).to(self.device)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, hc):\n",
    "        hc = self.rnn(x, hc)\n",
    "        out = self.fc(hc[0])\n",
    "        return out, hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss: 3.116730740349689\n",
      "Epoch 0 | Validation loss: 3.0181773584100267\n",
      "Epoch 1 | Training loss: 3.0453256907839865\n",
      "Epoch 1 | Validation loss: 3.0175540696216534\n",
      "Epoch 2 | Training loss: 3.0386348660700326\n",
      "Epoch 2 | Validation loss: 3.018032180357583\n",
      "Epoch 3 | Training loss: 3.0359601954998046\n",
      "Epoch 3 | Validation loss: 3.0195395003391217\n",
      "Epoch 4 | Training loss: 3.0315658178901153\n",
      "Epoch 4 | Validation loss: 3.0178465843200684\n",
      "Epoch 5 | Training loss: 3.0307984313133303\n",
      "Epoch 5 | Validation loss: 3.0202498632141306\n",
      "Epoch 6 | Training loss: 3.026304320353578\n",
      "Epoch 6 | Validation loss: 3.0197211677515052\n",
      "Epoch 7 | Training loss: 3.026444337673343\n",
      "Epoch 7 | Validation loss: 3.0217264528515972\n",
      "Epoch 8 | Training loss: 3.0237721864144222\n",
      "Epoch 8 | Validation loss: 3.0200215065026583\n",
      "Epoch 9 | Training loss: 3.0203142578660307\n",
      "Epoch 9 | Validation loss: 3.0237030251116694\n",
      "Epoch 10 | Training loss: 3.018739834143615\n",
      "Epoch 10 | Validation loss: 3.022883661185639\n",
      "Epoch 11 | Training loss: 3.014539259331103\n",
      "Epoch 11 | Validation loss: 3.0251460399808763\n",
      "Epoch 12 | Training loss: 3.0140446564157264\n",
      "Epoch 12 | Validation loss: 3.026062945776348\n",
      "Epoch 13 | Training loss: 3.017974958432793\n",
      "Epoch 13 | Validation loss: 3.033111347427851\n",
      "Epoch 14 | Training loss: 3.0098082048041945\n",
      "Epoch 14 | Validation loss: 3.0453778799576097\n",
      "Epoch 15 | Training loss: 3.0100498394355464\n",
      "Epoch 15 | Validation loss: 3.0348293290862554\n",
      "Epoch 16 | Training loss: 3.007676310370339\n",
      "Epoch 16 | Validation loss: 3.0433842388889456\n",
      "Epoch 17 | Training loss: 3.001882913002201\n",
      "Epoch 17 | Validation loss: 3.044651198990737\n",
      "Epoch 18 | Training loss: 2.9960975172734066\n",
      "Epoch 18 | Validation loss: 3.043569180029857\n",
      "Epoch 19 | Training loss: 2.99763157192303\n",
      "Epoch 19 | Validation loss: 3.0478076655653457\n",
      "Epoch 20 | Training loss: 2.9920196685868974\n",
      "Epoch 20 | Validation loss: 3.046551561053795\n",
      "Epoch 21 | Training loss: 2.9844388380362488\n",
      "Epoch 21 | Validation loss: 3.051772153075737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-d546d00c82c8>\", line 29, in <module>\n",
      "    loss.backward(retain_graph=True)\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\", line 102, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 90, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/capstone/anaconda3/envs/pytorch/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "feature_size = normalized_features.shape[1]\n",
    "\n",
    "model_params = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"input_dim\": feature_size,\n",
    "    \"hidden_dim\": 48,\n",
    "    \"num_layers\": 1\n",
    "}\n",
    "\n",
    "model = LANLModel(device, **model_params)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    hc = model.init_hidden(batch_size)\n",
    "    for idx, batch in enumerate(dataloaders['train']):\n",
    "        if idx == (len(dataloaders['train']) - 1):\n",
    "            continue\n",
    "        model.zero_grad()\n",
    "        features = batch['data'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        output, hc = model(features, hc)\n",
    "        loss = criterion(output.float(), target)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(dataloaders['train'])\n",
    "    print(\"Epoch {} | Training loss: {}\".format(epoch, train_loss))\n",
    "    \n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        hc = model.init_hidden(batch_size)\n",
    "        for idx, batch in enumerate(dataloaders['val']):\n",
    "            if idx == (len(dataloaders['val']) - 1):\n",
    "                continue\n",
    "            features = batch['data'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "            output, hc = model(features, hc)\n",
    "            loss = criterion(output.float(), target)\n",
    "            validation_loss += loss.item()\n",
    "    validation_loss /= len(dataloaders['val'])\n",
    "    print(\"Epoch {} | Validation loss: {}\".format(epoch, validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
