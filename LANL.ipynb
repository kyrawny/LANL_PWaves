{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL Earthquake Prediction Kaggle Competition 2019\n",
    "### Eric Yap, Joel Huang, Kyra Wang\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we present our work for the LANL Earthquake Prediction Kaggle Competition 2019. The goal of this competition is to use seismic signals to predict the timing of laboratory earthquakes. The data comes from a well-known experimental set-up used to study earthquake physics. The `acoustic_data` input signal is used to predict the time remaining before the next laboratory earthquake (`time_to_failure`).\n",
    "\n",
    "The training data is a single, continuous segment of experimental data. The test data consists of a folder containing many small segments. The data within each test file is continuous, but the test files do not represent a continuous segment of the experiment; thus, the predictions cannot be assumed to follow the same regular pattern seen in the training file.\n",
    "\n",
    "For each `seg_id` in the test folder, we need to predict a single `time_to_failure` corresponding to the time between the last row of the segment and the next laboratory earthquake.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Utility imports\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tick\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "else:\n",
    "    torch.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "As the training data and the test data are formatted differently, we must either preprocess the data such that the formats of both sets are the same, or ensure that our model is capable of predicting on the two different formats. We went with the first option because it is less time consuming to implement.\n",
    "\n",
    "We did this by splitting the training data into segments the same size as the test data segments, i.e. 150000 data points each. Each segment is labeled with a single `time_to_failure` corresponding to the time between the last row of the segment and the next laboratory earthquake. We then put each of these segments into a single dataframe, and saved this as a CSV file to be used as our training data.\n",
    "\n",
    "Following this, we merged the separate test segments into another single dataframe, and saved this as a CSV file to be used as our test data.\n",
    "\n",
    "As the dataset is massive, we used Joblib to help run the functions as a pipeline jobs with parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4195it [01:47, 38.87it/s]                          \n",
      "100%|██████████| 2624/2624 [00:27<00:00, 93.84it/s]\n"
     ]
    }
   ],
   "source": [
    "class FeatureGenerator(object):\n",
    "    def __init__(self, dtype, n_jobs=1, chunk_size=None):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dtype = dtype\n",
    "        self.filename = None\n",
    "        self.n_jobs = n_jobs\n",
    "        self.test_files = []\n",
    "        if self.dtype == 'train':\n",
    "            self.filename = './data/train.csv'\n",
    "            self.total_data = int(629145481 / self.chunk_size)\n",
    "        else:\n",
    "            submission = pd.read_csv('./data/sample_submission.csv')\n",
    "            for seg_id in submission.seg_id.values:\n",
    "                self.test_files.append((seg_id, './data/test/' + seg_id + '.csv'))\n",
    "            self.total_data = int(len(submission))\n",
    "\n",
    "    def read_chunks(self):\n",
    "        if self.dtype == 'train':\n",
    "            iter_df = pd.read_csv(self.filename, iterator=True, chunksize=self.chunk_size,\n",
    "                                  dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "            for counter, df in enumerate(iter_df):\n",
    "                x = df.acoustic_data.values\n",
    "                y = df.time_to_failure.values[-1]\n",
    "                seg_id = 'train_' + str(counter)\n",
    "                yield seg_id, x, y\n",
    "        else:\n",
    "            for seg_id, f in self.test_files:\n",
    "                df = pd.read_csv(f, dtype={'acoustic_data': np.int16})\n",
    "                x = df.acoustic_data.values\n",
    "                yield seg_id, x, -999\n",
    "\n",
    "    def features(self, x, y, seg_id):\n",
    "        feature_dict = dict()\n",
    "        feature_dict['target'] = y\n",
    "        feature_dict['segment'] = x\n",
    "        feature_dict['seg_id'] = seg_id\n",
    "\n",
    "        # create features here\n",
    "        # for example:\n",
    "        # feature_dict['mean'] = np.mean(x)\n",
    "\n",
    "        return feature_dict\n",
    "\n",
    "    def generate(self):\n",
    "        feature_list = []\n",
    "        res = Parallel(n_jobs=self.n_jobs,\n",
    "                       backend='threading')(delayed(self.features)(x, y, s)\n",
    "                                            for s, x, y in tqdm(self.read_chunks(), total=self.total_data))\n",
    "        for r in res:\n",
    "            feature_list.append(r)\n",
    "        return pd.DataFrame(feature_list)\n",
    "\n",
    "\n",
    "training_fg = FeatureGenerator(dtype='train', n_jobs=4, chunk_size=150000)\n",
    "training_data = training_fg.generate()\n",
    "\n",
    "test_fg = FeatureGenerator(dtype='test', n_jobs=4, chunk_size=None)\n",
    "test_data = test_fg.generate()\n",
    "\n",
    "training_data.to_csv(\"./data/train_features.csv\", index=False)\n",
    "test_data.to_csv(\"./data/test_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>segment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>[12, 6, 8, 5, 8, 8, 9, 7, -5, 3, 5, 2, 2, 3, -...</td>\n",
       "      <td>1.430797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>[5, 6, 8, 6, 3, -1, 5, 4, 4, 4, 6, 5, 5, 5, 6,...</td>\n",
       "      <td>1.391499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>[5, 5, 8, 9, 9, 10, 11, 12, 13, 5, 3, 7, 5, 3,...</td>\n",
       "      <td>1.353196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>[5, -5, -4, 1, 3, 4, 6, 12, 15, 17, 14, 9, 6, ...</td>\n",
       "      <td>1.313798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>[12, 6, 4, -1, 0, 6, 7, 6, 2, -2, 0, 4, 1, 5, ...</td>\n",
       "      <td>1.274400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seg_id                                            segment    target\n",
       "0  train_0  [12, 6, 8, 5, 8, 8, 9, 7, -5, 3, 5, 2, 2, 3, -...  1.430797\n",
       "1  train_1  [5, 6, 8, 6, 3, -1, 5, 4, 4, 4, 6, 5, 5, 5, 6,...  1.391499\n",
       "2  train_2  [5, 5, 8, 9, 9, 10, 11, 12, 13, 5, 3, 7, 5, 3,...  1.353196\n",
       "3  train_3  [5, -5, -4, 1, 3, 4, 6, 12, 15, 17, 14, 9, 6, ...  1.313798\n",
       "4  train_4  [12, 6, 4, -1, 0, 6, 7, 6, 2, -2, 0, 4, 1, 5, ...  1.274400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>segment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>[4, 0, -2, 0, 2, -3, -9, -4, 11, 11, 8, 1, 10,...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>[5, 8, 8, 7, 4, 1, -1, -4, -1, 0, 5, 7, -1, 7,...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>[8, 2, 3, 8, 7, 9, 7, 4, 4, 9, 9, 1, 2, 6, 4, ...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>[2, 6, 3, 6, 8, 6, 8, 5, 4, 6, 2, 3, 1, 4, 6, ...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>[5, 3, 1, 4, 6, 6, 7, 4, 5, 4, 3, 4, 6, 7, 3, ...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id                                            segment  target\n",
       "0  seg_00030f  [4, 0, -2, 0, 2, -3, -9, -4, 11, 11, 8, 1, 10,...    -999\n",
       "1  seg_0012b5  [5, 8, 8, 7, 4, 1, -1, -4, -1, 0, 5, 7, -1, 7,...    -999\n",
       "2  seg_00184e  [8, 2, 3, 8, 7, 9, 7, 4, 4, 9, 9, 1, 2, 6, 4, ...    -999\n",
       "3  seg_003339  [2, 6, 3, 6, 8, 6, 8, 5, 4, 6, 2, 3, 1, 4, 6, ...    -999\n",
       "4  seg_0042cc  [5, 3, 1, 4, 6, 6, 7, 4, 5, 4, 3, 4, 6, 7, 3, ...    -999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LANL_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LANL_Model, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
